---
title: "Edx HarvardX Data Science Capstone Project"
author: "Daniel Yoo"
date: "3/5/2020"
output: 
    pdf_document:
        toc: true
        number_sections: true
---

<style type="text/css">
div#TOC li {
    list-style:none;
    background-image:none;
    background-repeat:none;
    background-position:0; 
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```


# Introduction


Recommendation systems use ratings that users have given items to make specific recommendations. Companies that sell many products to many customers and permit these customers to rate their products, like Amazon, are able to collect massive datasets that can be used to predict what rating a particular user will give a specific item. Items for which a high rating is predicted for a given user are then recommended to that user.

Netflix uses a recommendation system to predict how many stars a user will give a specific movie. One star suggests it is not a good movie, whereas five stars suggests it is an excellent movie. Here, we provide the basics of how these recommendations are made, motivated by some of the approaches taken by the winners of the Netflix challenges.

In this project, we use the movielens dataset by the GroupLens research lab. Our primary goal of this study is to build a robust movie recommendation system using the offered dataset to reach the aimed perfomance root mean squared error (RMSE) less than 0.86490 on the validation set.
The project is part of the HarvardX's Data Science Professional Certificate program.


This report is composed of as follows. 

1. Introduction
2. Exploratory Data Analysis
3. Modeling
4. Results (validation)
5. Conclusion


# Exploratoy Data Analysis (EDA)


First, we load the dataset as the project instruction describes.


```{r, echo = T, warning=FALSE, message=FALSE}
# First load packages
library(ggplot2)
library(tidyverse)
library(kableExtra)
library(recosystem)
library(data.table)
```


```{r, cache=TRUE}
################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
# set.seed(1, sample.kind="Rounding")
set.seed(1)
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
    semi_join(edx, by = "movieId") %>%
    semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```


Now, we see the basic structure of the dataset.

```{r basic EDA}
edx %>% class()
dim(edx)
head(edx)

edx %>% 
  summarise(users = n_distinct(userId),
            movies = n_distinct(movieId))
edx %>%
  select(genres) %>% 
  separate_rows(genres, sep = "\\|") %>% 
  pull(genres) %>% unique()
```

There are 69878 users and 10677 movies included in the dataset.
There are 20 genres. However, one genre is (no genres listed) which is obscure.


```{r check_na}
# check any missing data
any(is.na(edx))
```

## EDA by movie

Let's look at the basics of the rated movies.
```{r edx_movies}
edx_movies <- 
  edx %>% 
  group_by(movieId) %>% 
  summarise(count = n()) %>% 
  arrange(-count)
edx_movies %>% summary()
```

The most reviewed movie was rated by `r max(edx_movies$count)` users and the least reviewed movie was rated by `r min(edx_movies$count)` user. The median and mean of the number of rating for the entire movie was `r median(edx_movies$count)` and `r mean(edx_movies$count)`, respectively.

```{r, cache=TRUE, fig.height=14, fig.width=10}
# What are the most rated movies?
edx %>% 
  group_by(title) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  top_n(10) %>% 
  ggplot(aes(x = reorder(title, -count), y = count)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1)) +
  xlab("Top 10 most rated movies")

# What are the best rated movies?
edx %>% 
  group_by(title) %>% 
  filter(n() >= 1000) %>%  
  summarise(avg = mean(rating), median = median(rating), n = n()) %>% 
  arrange(-avg) %>% 
  top_n(10) %>% 
  ggplot(aes(reorder(title, -avg), avg)) +
  geom_bar(stat = "identity") +
  xlab("") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1, size = 15)) +
  ylab("Average rating") + ggtitle("Top 10 best rated movies which at least received 1000 ratings")

# What are the most rated genres?
edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(count = n()) %>% 
  arrange(-count)

edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(reorder(genres, -count), count)) +
  geom_bar(stat = "identity") +
  xlab("") +
  theme(axis.text.x = element_text(size = 15, angle = 90, hjust = 1, vjust = 0)) +
  ggtitle("Number of rated genres")

# What are the best rated genres?
edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(avg = mean(rating), median = median(rating), count = n()) %>% 
  ggplot(aes(reorder(genres, -avg), avg)) +
  geom_bar(stat = "identity") +
  xlab("") +
  theme(axis.text.x = element_text(size = 15, angle = 90, hjust = 1, vjust = 0)) +
  ylab("Average rating")
  ggtitle("Average Rates of genres")
```

We can see that drama, comedy and action are the most commonly rated genres. We can assume this is by the popular hollywood movies. The top rated movies are film-noir, documentary, and war movies. We can safely assume that this is because of the users who watch these movies tend to rate better.
Note that there are 7 unspecified genre movies. The average rating for this movie is not meaningful due to the lack of users.


## EDA by user


```{r, cache=TRUE}
# Who has rated the most movies?
edx %>% 
  group_by(userId) %>% 
  summarise(avg = mean(rating),
            median = median(rating),
            count = n()) %>% 
  summary()


```

We can see that the most active user rated 6616 movies. The least active user rated 10 movies. The average rating is 3.6. The average number of rating per user is 129.

```{r}
# Ratings are normally distributed
edx %>% 
  group_by(userId) %>% 
  summarise(mean = mean(rating),
            median = median(rating)) %>% 
  ggplot() +
  geom_density(aes(mean, fill = "mean"), alpha = 0.3) +
  geom_density(aes(median, fill = "median"), alpha = 0.3) +
  xlab("Rating") +
  ylab("Density") +
  ggtitle("Users' average ratings") +
  labs(fill = "")

# Users' activity
edx %>% 
  group_by(userId) %>% 
  summarise(count = n()) %>% 
  ggplot() +
  geom_density(aes(count, fill = "count"), alpha = 0.3) +
  xlab("Count") +
  ylab("Density") +
  ggtitle("Users' activity") +
  labs(fill = "")
```

As expected, users' ratings are normally distributed. Also, users' activities are poisson distribution, highly skewed.


# Modeling

We use root mean square error as a metric to judge our model performance.

First, we will make an extra test set to check the performance of our models before testing on the final validation dataset.

```{r split_data}
# split train and test sets
set.seed(1)
ind <- createDataPartition(y = edx$rating, times = 1, p = 0.3, list = F)
train_set <- edx[-ind, ]
test_set <- edx[-ind, ]

# semi_join to double check that all users and movies in the test set are also included in the train set
test_set <- 
  test_set %>% 
  semi_join(train_set, by = "movieId") %>% 
  semi_join(train_set, by = "userId")

```



## Simplest Model

Here, we will build the simplest model. Using the arithmetic mean to predict.

```{r simple_average}
mu_hat <- mean(train_set$rating)
naive_rmse <- RMSE(mu_hat, test_set$rating)

# create a data frame to keep the performances for different models
rmse_results <- tibble(
  method = c("Project goal", "Simple average"),
  RMSE = c(0.86490, naive_rmse)
)
mu_hat
rmse_results %>% kable()
```
The average rating of all movies across all users is `r mu_hat`. 

The RMSE with the simple mean is `r naive_rmse`.


## Adding movie effects

We can do better with adding effects. First, we add movie effects.

```{r movie_effect}
mu <- mean(train_set$rating)
movie_avgs <- train_set %>% 
    group_by(movieId) %>% 
    summarise(b_i = mean(rating - mu))

qplot(b_i, data = movie_avgs, bins = 10, color = I("black"))

predicted_ratings <- mu + test_set %>% 
    left_join(movie_avgs, by = "movieId") %>% 
    pull(b_i)
movie_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results, tibble(
    method = "Movie Effect",
    RMSE = movie_rmse)
)
rmse_results %>% kable()
```

We see that adding movie effect has made great improvements in our metric. Now our RMSE is under 0.95.


## Adding user effects

Second, we add user effects.
```{r user_effect}
# Calculate user effects
user_avgs <- 
  train_set %>% 
  left_join(movie_avgs, by = "movieId") %>% 
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i))

# Predict
predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by = "movieId") %>% 
  left_join(user_avgs, by = "userId") %>% 
  mutate(pred = mu + b_i + b_u) %>% 
  pull(pred)

movie_user_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- 
  rmse_results %>% 
  bind_rows(tibble(
    method = "Movie + User Effects",
    RMSE = movie_user_rmse
  ))
rmse_results %>% kable()
```

We have made another great achievement by adding user effects on top of the movie effect. It is less than our first aimed RMSE 0.86490. However, we can do better by trying regularization.


## Regularization
The largest and smallest movie and user effects are with movies and users with only few ratings.
So we use regularization to penalize such estimates that come from small sizes.
We use cross-validation to find the best tuning parameter. 

*Note:* this process might take some time.

```{r regularization}
# cross-validation

lambdas <- seq(0, 10, 0.5)
lambda_look <- function(l, train_set, test_set) {
  mu <- mean(train_set$rating)
  b_i <- train_set %>% 
    group_by(movieId) %>% 
    summarise(b_i = sum(rating - mu) / (n() + l))
  
  b_u <- train_set %>% 
    left_join(b_i, by = "movieId") %>% 
    group_by(userId) %>% 
    summarise(b_u = sum(rating - mu - b_i) / (n() + l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>% 
    left_join(b_u, by = "userId") %>% 
    mutate(pred = mu + b_i + b_u) %>% 
    pull(pred)
  RMSE(predicted_ratings, test_set$rating)
}

rmses <- sapply(lambdas, lambda_look, train_set = train_set, test_set = test_set)
qplot(lambdas, rmses)

# more specified search
lambdas <- seq(0, 1, 0.1)
rmses <- sapply(lambdas, lambda_look, train_set = train_set, test_set = test_set)
qplot(lambdas, rmses)
lambdas[which.min(rmses)]

l <- 0.4
mu <- mean(train_set$rating)
b_i <- train_set %>% 
  group_by(movieId) %>% 
  summarise(b_i = sum(rating - mu) / (n() + l))

b_u <- train_set %>% 
  left_join(b_i, by = "movieId") %>% 
  group_by(userId) %>% 
  summarise(b_u = sum(rating - mu - b_i) / (n() + l))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>% 
  left_join(b_u, by = "userId") %>% 
  mutate(pred = mu + b_i + b_u) %>% 
  pull(pred)
regularized_RMSE <- RMSE(predicted_ratings, test_set$rating)
rmse_results <-
  rmse_results %>% 
  bind_rows(tibble(
    method = "Movie, User Effects, Regularized",
    RMSE = regularized_RMSE
  ))
rmse_results %>% kable()
```
We made a very tiny improvement by searching lambda. This may due to our high proportion, 70% of training partition.


## Matrix Factorization

Matrix factorization is a widely used concept in machine learning. It is very much related to factor analysis, singular value decomposition (SVD), and principal component analysis (PCA). 

We use `recosystem` R package developed by Yu-Chin Juan, Wei-Sheng Chin, Yong Zhuang, Bo-Wen Yuan, Meng-Yuan Yang, and Chih-Jen Lin, an open source library for recommender system using parallel matrix factorization.
[github page](https://github.com/yixuan/recosystem)

```{r recosystem, message=FALSE, cache=TRUE}
library(recosystem)
set.seed(123)
train_data <- with(train_set,
                   data_memory(user_index = userId,
                               item_index = movieId,
                               rating = rating))
test_data <- with(test_set,
                   data_memory(user_index = userId,
                               item_index = movieId,
                               rating = rating))

r <- recosystem::Reco()

# we perform without extra tuning process for the sake of simplicity
r$train(train_data, opts = c(niter = 60))
y_hat_reco <- r$predict(test_data, out_memory())
rmse_results <- bind_rows(rmse_results,
                    tibble(
                        method = "Matrix Factorization",
                        RMSE = RMSE(y_hat_reco, test_set$rating)
                    ))
rmse_results %>% kable()
```
We observe a great improvements from the matrix factorization. Now we are ready to test this in the real validation set.

# Results (validation)

We already observed that the RMSE by linear model successfully achieved the aimed RMSE on the test set. In addition, we went further to minimize RMSE value by using the matrix factorization.
Here, we test whether our models perform as we expect or not.

```{r validation, cache=TRUE}
# Since we finished finding our hyperparameter, lambda, we can use the whole edx set from now on.
mu_final <- mean(edx$rating)

# movie effect
b_i_final <- 
  edx %>% 
  group_by(movieId) %>% 
  summarise(b_i_final = sum(rating - mu_final) / (n() + l))

# user effect
b_u_final <- 
  edx %>% 
  left_join(b_i_final, by = "movieId") %>% 
  group_by(userId) %>% 
  summarise(b_u_final = sum(rating - mu_final - b_i_final) / (n() + l))

pred_validation <- 
  validation %>% 
  left_join(b_i_final, by = "movieId") %>% 
  left_join(b_u_final, by = "userId") %>% 
  mutate(pred_final = mu_final + b_i_final + b_u_final) %>% 
  pull(pred_final)

RMSE_validation_regularized <- RMSE(pred_validation, validation$rating)
rmse_results <- 
  rmse_results %>% 
  bind_rows(
    tibble(
      method = "Movie, User Effects, Regularized (validation)",
      RMSE = RMSE_validation_regularized
    )
            )
rmse_results %>% kable()
```

Here, we observe that our regularized model does not perform as good as on the test set. Let's try our matrix factorization model.

```{r matrix_factorization_validation, message=F, cache=T}
set.seed(123)
train_data <- with(edx,
                   data_memory(user_index = userId,
                               item_index = movieId,
                               rating = rating))
test_data <- with(validation,
                   data_memory(user_index = userId,
                               item_index = movieId,
                               rating = rating))

r <- recosystem::Reco()

# we perform without extra tuning process for the sake of simplicity
r$train(train_data, opts = c(niter = 60))
y_hat_reco <- r$predict(test_data, out_memory())
rmse_results <- bind_rows(rmse_results,
                    tibble(
                        method = "Matrix Factorization (validation)",
                        RMSE = RMSE(y_hat_reco, validation$rating)
                    ))
rmse_results %>% kable()
```

The final RMSE with matrix factorization on the validation set is less than our aimed RMSE score.


# Conclusion

We used movielens dataset to construct a recommender system through HarvardX Data Science Capstone project. We built both linear models and matrix factorized model. We observed that adding movie and user effects could significantly improve the performance of model. We could finally achieved to reach our aimed RMSE score by using our final matrix factozied model.
Our model has several weaknesses. First, we only used two predictors, user and movie information. Second, our model is built for existing users so the implementation on a new user would be time-consuming process by running a new model each time.



